{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb0e4886-c222-4183-89a7-f077e3b1a105",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the project's files to the python path\n",
    "# file_path = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))  # for .py script\n",
    "file_path = os.path.dirname(os.path.abspath(''))  # for .ipynb notebook\n",
    "sys.path.append(file_path)\n",
    "\n",
    "import hydra\n",
    "from src.utils import init_config, compute_panoptic_metrics, \\\n",
    "    compute_panoptic_metrics_s3dis_6fold, grid_search_panoptic_partition, \\\n",
    "    oracle_superpoint_clustering\n",
    "import torch\n",
    "from src.transforms import *\n",
    "from src.utils.widgets import *\n",
    "from src.data import *\n",
    "\n",
    "# Very ugly fix to ignore lightning's warning messages about the\n",
    "# trainer and modules not being connected\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452559c9-8fbc-4685-bbaf-c6e4ac24cbc7",
   "metadata": {},
   "source": [
    "## Select your device, experiment, split, and pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06a233bd-12c8-415a-a922-222a925733f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6b788924c24fdd8acc4d5685feee4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='üëâ Choose a device:', options=(device(type='cpu'), device(type='cuda', index=0), dev‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a60d620b6343b6a2dfac6d0d0cc1ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='üëâ Choose a segmentation task:', options=('semantic', 'panoptic'), value='semantic')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89be3207848646429c1f00ce286121e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='üëâ Choose an experiment:', options=('dales', 'dales_11g', 'dales_nano', 'kitti360', ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fff514bae1ae4ec9be7cb813ddec3cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='üëâ Choose a data split:', index=1, options=('train', 'val', 'test'), value='val')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de931255ff18435386d0a4b76021d73a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/home/binahlab/AI-Labs/superpoint_transformer/notebooks', filename='', title='', show_hidden‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device_widget = make_device_widget()\n",
    "task_widget, expe_widget = make_experiment_widgets()\n",
    "split_widget = make_split_widget()\n",
    "ckpt_widget = make_checkpoint_file_search_widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f63dd77-81d4-4245-90f3-0267371dea52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You chose:\n",
      "  - device=cuda:0\n",
      "  - task=panoptic\n",
      "  - split=train\n",
      "  - experiment=kitti360_11g\n",
      "  - ckpt=/home/binahlab/AI-Labs/superpoint_transformer/ckpt/supercluster_kitti360.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Summarizing selected task, experiment, split, and checkpoint\n",
    "print(f\"You chose:\")\n",
    "print(f\"  - device={device_widget.value}\")\n",
    "print(f\"  - task={task_widget.value}\")\n",
    "print(f\"  - split={split_widget.value}\")\n",
    "print(f\"  - experiment={expe_widget.value}\")\n",
    "print(f\"  - ckpt={ckpt_widget.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1353339e-281c-48b9-b5df-c3abf9f1a64e",
   "metadata": {},
   "source": [
    "## Parsing the config files\n",
    "Hydra and OmegaConf are used to parse the `yaml` config files.\n",
    "\n",
    "‚ùóMake sure you selected a **ckpt file relevant to your experiment** in the previous section. \n",
    "You can use our pretrained models for this, or your own checkpoints if you have already trained a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ebc1dbb-3c8e-451a-ac24-3cb8df0c28a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the configs using hydra\n",
    "cfg = init_config(overrides=[\n",
    "    f\"experiment={task_widget.value}/{expe_widget.value}\",\n",
    "    f\"ckpt_path={ckpt_widget.value}\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47121b17-c514-40e9-b441-a6d695cce8c1",
   "metadata": {},
   "source": [
    "## Datamodule and model instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdd9594b-6d5c-43f7-99e4-e37ae7e985c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/binahlab/AI-Labs/clever-data/electrical-elements/data/\n",
      "0   road                 stuff\n",
      "1   sidewalk             stuff\n",
      "2   building             thing\n",
      "3   wall                 stuff\n",
      "4   fence                stuff\n",
      "5   pole                 stuff\n",
      "6   traffic light        stuff\n",
      "7   traffic sign         stuff\n",
      "8   vegetation           stuff\n",
      "9   terrain              stuff\n",
      "10  person               stuff\n",
      "11  car                  thing\n",
      "12  truck                stuff\n",
      "13  motorcycle           stuff\n",
      "14  bicycle              stuff\n",
      "15  ignored              void\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the datamodule\n",
    "datamodule = hydra.utils.instantiate(cfg.datamodule)\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup()\n",
    "\n",
    "# Pick among train, val, and test datasets. It is important to note that\n",
    "# the train dataset produces augmented spherical samples of large \n",
    "# scenes, while the val and test dataset load entire tiles at once\n",
    "if split_widget.value == 'train':\n",
    "    dataset = datamodule.train_dataset\n",
    "elif split_widget.value == 'val':\n",
    "    dataset = datamodule.val_dataset\n",
    "elif split_widget.value == 'test':\n",
    "    dataset = datamodule.test_dataset\n",
    "else:\n",
    "    raise ValueError(f\"Unknown split '{split_widget.value}'\")\n",
    "\n",
    "# Print a summary of the datasets' classes\n",
    "dataset.print_classes()\n",
    "\n",
    "# Instantiate the model\n",
    "model = hydra.utils.instantiate(cfg.model)\n",
    "\n",
    "# Load pretrained weights from a checkpoint file\n",
    "if ckpt_widget.value is not None:\n",
    "    model = model._load_from_checkpoint(cfg.ckpt_path)\n",
    "\n",
    "# Move model to selected device\n",
    "model = model.eval().to(device_widget.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9546ad1-f819-44d9-b2b7-343e96b72efb",
   "metadata": {},
   "source": [
    "## Oracles on a tile sample\n",
    "We design oracles for estimating the maximum achievable performance of our superpoint-graph-clustering approach on a point cloud. Here, it is important to note that these metrics are computed on a tile but not on the entire dataset. The oracles are computed on a given superpoint partition level. Based on the quality of the partition, we estimate the following:\n",
    "\n",
    "- `semantic_segmentation_oracle`: assign to each superpoint the most frequent label among the points it contains\n",
    "- `panoptic_segmentation_oracle`: same as for semantic segmentation + assign each superpoint to the target instance it overlaps the most\n",
    "- `oracle_superpoint_clustering`: same as for semantic segmentation + assign to each edge the target affinity + compute the graph clustering to form instance predictions\n",
    "\n",
    "Of course, these oracles are affected by how the superpoint partition has been computed. Besides, the latter is also affected by the graph clustering parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21614c71-e332-439e-8fe7-bd51825e4e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the panoptic annotations for a tile from the dataset \n",
    "obj = dataset[0][1].obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "010bba12-6161-45ee-9af3-64183f51588b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'oa': tensor(99.1097),\n",
       " 'macc': tensor(98.0919),\n",
       " 'miou': tensor(96.2796),\n",
       " 'iou_per_class': tensor([9.9268e+01, 9.1135e+01, 9.9191e+01, 1.0000e-06, 1.0000e-06, 9.3546e+01,\n",
       "         1.0000e-06, 9.3659e+01, 9.8860e+01, 9.4754e+01, 1.0000e-06, 9.9825e+01,\n",
       "         1.0000e-06, 1.0000e-06, 1.0000e-06]),\n",
       " 'seen_class': tensor([ True,  True,  True, False, False,  True, False,  True,  True,  True,\n",
       "         False,  True, False, False, False])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the semantic segmentation oracle\n",
    "obj.semantic_segmentation_oracle(dataset.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c1a4cba-bac7-485d-a72d-5afc9aea3958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pq': tensor(0.9623),\n",
       " 'sq': tensor(0.9623),\n",
       " 'rq': tensor(1.),\n",
       " 'pq_modified': tensor(0.9623),\n",
       " 'pq_thing': tensor(0.9932),\n",
       " 'sq_thing': tensor(0.9932),\n",
       " 'rq_thing': tensor(1.),\n",
       " 'pq_stuff': tensor(0.9520),\n",
       " 'sq_stuff': tensor(0.9520),\n",
       " 'rq_stuff': tensor(1.),\n",
       " 'pq_per_class': tensor([0.9927, 0.9113, 0.9909,    nan,    nan, 0.9355,    nan, 0.9366, 0.9886,\n",
       "         0.9475,    nan, 0.9954,    nan,    nan,    nan]),\n",
       " 'sq_per_class': tensor([0.9927, 0.9113, 0.9909,    nan,    nan, 0.9355,    nan, 0.9366, 0.9886,\n",
       "         0.9475,    nan, 0.9954,    nan,    nan,    nan]),\n",
       " 'rq_per_class': tensor([1., 1., 1., nan, nan, 1., nan, 1., 1., 1., nan, 1., nan, nan, nan]),\n",
       " 'precision_per_class': tensor([1., 1., 1., nan, nan, 1., nan, 1., 1., 1., nan, 1., nan, nan, nan]),\n",
       " 'recall_per_class': tensor([1., 1., 1., nan, nan, 1., nan, 1., 1., 1., nan, 1., nan, nan, nan]),\n",
       " 'tp_per_class': tensor([1, 1, 3, 0, 0, 1, 0, 1, 1, 1, 0, 9, 0, 0, 0]),\n",
       " 'fp_per_class': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'fn_per_class': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'pq_modified_per_class': tensor([0.9927, 0.9113, 0.9909,    nan,    nan, 0.9355,    nan, 0.9366, 0.9886,\n",
       "         0.9475,    nan, 0.9954,    nan,    nan,    nan]),\n",
       " 'mean_precision': tensor(1.),\n",
       " 'mean_recall': tensor(1.)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the panoptic segmentation oracle without graph clustering\n",
    "obj.panoptic_segmentation_oracle(dataset.num_classes, stuff_classes=dataset.stuff_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a43b3ccb-bd92-4c30-8a35-8ef4037bd0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pq': tensor(0.6792),\n",
       " 'sq': tensor(0.8376),\n",
       " 'rq': tensor(0.7759),\n",
       " 'pq_modified': tensor(0.6792),\n",
       " 'pq_thing': tensor(0.0862),\n",
       " 'sq_thing': tensor(0.7199),\n",
       " 'rq_thing': tensor(0.1036),\n",
       " 'pq_stuff': tensor(0.8769),\n",
       " 'sq_stuff': tensor(0.8769),\n",
       " 'rq_stuff': tensor(1.),\n",
       " 'pq_per_class': tensor([0.9799, 0.7806, 0.0181,    nan,    nan, 0.7657,    nan, 0.8563, 0.9837,\n",
       "         0.8952,    nan, 0.1542,    nan,    nan,    nan]),\n",
       " 'sq_per_class': tensor([0.9799, 0.7806, 0.5574,    nan,    nan, 0.7657,    nan, 0.8563, 0.9837,\n",
       "         0.8952,    nan, 0.8824,    nan,    nan,    nan]),\n",
       " 'rq_per_class': tensor([1.0000, 1.0000, 0.0325,    nan,    nan, 1.0000,    nan, 1.0000, 1.0000,\n",
       "         1.0000,    nan, 0.1748,    nan,    nan,    nan]),\n",
       " 'precision_per_class': tensor([1.0000, 1.0000, 0.0167,    nan,    nan, 1.0000,    nan, 1.0000, 1.0000,\n",
       "         1.0000,    nan, 0.0957,    nan,    nan,    nan]),\n",
       " 'recall_per_class': tensor([1.0000, 1.0000, 0.6667,    nan,    nan, 1.0000,    nan, 1.0000, 1.0000,\n",
       "         1.0000,    nan, 1.0000,    nan,    nan,    nan]),\n",
       " 'tp_per_class': tensor([1, 1, 2, 0, 0, 1, 0, 1, 1, 1, 0, 9, 0, 0, 0]),\n",
       " 'fp_per_class': tensor([  0,   0, 118,   0,   0,   0,   0,   0,   0,   0,   0,  85,   0,   0,\n",
       "           0]),\n",
       " 'fn_per_class': tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'pq_modified_per_class': tensor([0.9799, 0.7806, 0.0181,    nan,    nan, 0.7657,    nan, 0.8563, 0.9837,\n",
       "         0.8952,    nan, 0.1542,    nan,    nan,    nan]),\n",
       " 'mean_precision': tensor(0.7641),\n",
       " 'mean_recall': tensor(0.9583)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the panoptic segmentation oracle with graph clustering\n",
    "oracle_superpoint_clustering(\n",
    "    dataset[0],\n",
    "    dataset.num_classes,\n",
    "    dataset.stuff_classes,\n",
    "    mode='pas',\n",
    "    graph_kwargs=dict(\n",
    "        radius=0.1),\n",
    "    partition_kwargs=dict(\n",
    "        regularization=0.1,\n",
    "        x_weight=1e-3,\n",
    "        cutoff=300))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e4f497-91b8-4ad0-88dc-aaecf6b0f5e0",
   "metadata": {},
   "source": [
    "## Grid-searching partition parameters on a tile sample\n",
    "Our SuperCluster model is trained to predict the input for a graph clustering problem whose solution is a panoptic segmentation of the scene.\n",
    "Interestingly, with our formulation, the model is **only supervised with local node-wise and edge-wise objectives, without ever needing to compute an actual panoptic partition of the scene during training**.\n",
    "\n",
    "At inference time, however, we need to decide on some parameters for our graph clustering algorithm.\n",
    "To this end, a simple post-training grid-search can be used.\n",
    "\n",
    "We find that similar parameters maximize panoptic segmentation results on all our datasets. \n",
    "Here you, we provide utilities for helping you grid-search parameters yourself. See `grid_search_panoptic_partition` docstring for more details on how to use this tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16ddc046-dd0a-4366-8169-0e96b707e3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    regul.    x_wei.  cutoff     PQ     SQ     RQ\n",
      "0     20.0  5.00e-02     300  38.76  52.11  51.90\n",
      "1     20.0  1.00e-02     300  32.79  46.51  41.91\n",
      "2     20.0  1.00e-03     300  32.81  46.57  41.91\n",
      "3     20.0  1.00e-04     300  32.78  46.65  41.91\n",
      "4     10.0  5.00e-02     300  38.90  52.68  51.86\n",
      "5     10.0  1.00e-02     300  39.16  52.64  51.91\n",
      "6     10.0  1.00e-03     300  32.77  46.36  41.91\n",
      "7     10.0  1.00e-04     300  32.77  46.47  41.91\n",
      "8      5.0  5.00e-02     300  32.18  45.65  41.85\n",
      "9      5.0  1.00e-02     300  32.58  45.93  41.90\n",
      "10     5.0  1.00e-03     300  32.61  46.18  41.91\n",
      "11     5.0  1.00e-04     300  32.85  46.56  41.91\n",
      "\n",
      "\n",
      "Best panoptic setup: PQ=39.16\n",
      "   regul.  x_wei.  cutoff\n",
      "0    10.0    0.01     300\n",
      "\n",
      "                  PQ     SQ      RQ   PREC.   REC.   TP      FP    FN\n",
      "road           90.15  90.15  100.00  100.00  100.0  1.0     0.0   0.0\n",
      "sidewalk       76.64  76.64  100.00  100.00  100.0  1.0     0.0   0.0\n",
      "building        0.62  66.09    0.94    0.47   37.5  6.0  1261.0  10.0\n",
      "wall           54.54  54.54  100.00  100.00  100.0  1.0     0.0   0.0\n",
      "fence           0.00   0.00    0.00    0.00    0.0  0.0     1.0   1.0\n",
      "pole           63.26  63.26  100.00  100.00  100.0  1.0     0.0   0.0\n",
      "traffic light    NaN    NaN     NaN     NaN    NaN  0.0     0.0   0.0\n",
      "traffic sign     NaN    NaN     NaN     NaN    NaN  0.0     0.0   0.0\n",
      "vegetation     91.02  91.02  100.00  100.00  100.0  1.0     0.0   0.0\n",
      "terrain         0.00   0.00    0.00    0.00    0.0  0.0     0.0   1.0\n",
      "person           NaN    NaN     NaN     NaN    NaN  0.0     0.0   0.0\n",
      "car            15.41  84.74   18.18   10.14   87.5  7.0    62.0   1.0\n",
      "truck            NaN    NaN     NaN     NaN    NaN  0.0     0.0   0.0\n",
      "motorcycle       NaN    NaN     NaN     NaN    NaN  0.0     0.0   0.0\n",
      "bicycle         0.00   0.00    0.00    0.00    NaN  0.0     1.0   0.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Grid search graph clustering parameters\n",
    "output, partitions, results = grid_search_panoptic_partition(\n",
    "    model,\n",
    "    datamodule.val_dataset,\n",
    "    i_cloud=0,\n",
    "    graph_kwargs=dict(\n",
    "        radius=0.1),\n",
    "    partition_kwargs=dict(\n",
    "        regularization=[2e1, 1e1, 5],\n",
    "        x_weight=[5e-2, 1e-2, 1e-3, 1e-4],\n",
    "        cutoff=300),\n",
    "    mode='pas')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2200c0b8-9af0-40d3-828a-26e76bd2c2e4",
   "metadata": {},
   "source": [
    "## Running evaluation on a whole dataset\n",
    "The above grid search only computes the panoptic segmentation metrics on a single point cloud.\n",
    "In this section, we provide tools for computing the panoptic metrics on a whole dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb38437f-90cd-47e1-bd11-8a3eba25dfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/244 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "PanopticSegmentationModule is not attached to a `Trainer`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m panoptic, instance, semantic \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_panoptic_metrics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mradius\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartition_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregularization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5e-2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AI-Labs/superpoint_transformer/src/utils/instance.py:910\u001b[0m, in \u001b[0;36mcompute_panoptic_metrics\u001b[0;34m(model, datamodule, stage, graph_kwargs, partition_kwargs, verbose)\u001b[0m\n\u001b[1;32m    906\u001b[0m     nag \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mon_device_transform(nag)\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;66;03m# NB: we use the \"validation_step\" protocol here, regardless\u001b[39;00m\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;66;03m# of the stage the data comes from\u001b[39;00m\n\u001b[0;32m--> 910\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;66;03m# Actions taken from on_validation_epoch_end()\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;66;03m# panoptic_results = model.val_panoptic.compute()\u001b[39;00m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;66;03m# instance_miou = model.val_semantic.miou()\u001b[39;00m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;66;03m# instance_oa = model.val_semantic.oa()\u001b[39;00m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;66;03m# instance_macc = model.val_semantic.macc()\u001b[39;00m\n\u001b[1;32m    917\u001b[0m panoptic \u001b[38;5;241m=\u001b[39m deepcopy(model\u001b[38;5;241m.\u001b[39mval_panoptic)\n",
      "File \u001b[0;32m~/AI-Labs/superpoint_transformer/src/models/semantic.py:687\u001b[0m, in \u001b[0;36mSemanticSegmentationModule.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    685\u001b[0m track_all_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39mtrack_val_idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m track_epoch \u001b[38;5;129;01mand\u001b[39;00m (track_batch \u001b[38;5;129;01mor\u001b[39;00m track_all_batches):\n\u001b[0;32m--> 687\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;66;03m# Explicitly delete the output, for memory release\u001b[39;00m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m output\n",
      "File \u001b[0;32m~/AI-Labs/superpoint_transformer/src/models/panoptic.py:1466\u001b[0m, in \u001b[0;36mPanopticSegmentationModule.track_batch\u001b[0;34m(self, batch, batch_idx, output, folder)\u001b[0m\n\u001b[1;32m   1463\u001b[0m batch[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39medge_affinity_logits \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39medge_affinity_logits\n\u001b[1;32m   1465\u001b[0m \u001b[38;5;66;03m# Parent behavior for saving semantic segmentation prediction\u001b[39;00m\n\u001b[0;32m-> 1466\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfolder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AI-Labs/superpoint_transformer/src/models/semantic.py:947\u001b[0m, in \u001b[0;36mSemanticSegmentationModule.track_batch\u001b[0;34m(self, batch, batch_idx, output, folder)\u001b[0m\n\u001b[1;32m    944\u001b[0m batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m    946\u001b[0m \u001b[38;5;66;03m# Prepare the folder\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m     stage \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munknown_stage\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtraining:\n",
      "File \u001b[0;32m~/miniconda3/envs/spt/lib/python3.8/site-packages/pytorch_lightning/core/module.py:218\u001b[0m, in \u001b[0;36mLightningModule.trainer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _TrainerFabricShim(fabric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fabric)  \u001b[38;5;66;03m# type: ignore[return-value]\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_is_scripting \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not attached to a `Trainer`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\n",
      "\u001b[0;31mRuntimeError\u001b[0m: PanopticSegmentationModule is not attached to a `Trainer`."
     ]
    }
   ],
   "source": [
    "panoptic, instance, semantic = compute_panoptic_metrics(\n",
    "    model,\n",
    "    datamodule,\n",
    "    stage='val',\n",
    "    graph_kwargs=dict(\n",
    "        radius=0.1),\n",
    "    partition_kwargs=dict(\n",
    "        regularization=1e1,\n",
    "        x_weight=5e-2,\n",
    "        cutoff=300))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b789ae6f-771d-4500-a7e0-6cd9e391bb45",
   "metadata": {},
   "source": [
    "### S3DIS 6-fold metrics\n",
    "For S3DIS 6-fold metrics, we provide the following utility for computing metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e3e09a-cae1-41b1-b4bc-9fb5834368a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_ckpt = {\n",
    "    1: \"/path/to/your/s3dis/checkpoint/fold_1.ckpt\",\n",
    "    2: \"/path/to/your/s3dis/checkpoint/fold_2.ckpt\",\n",
    "    3: \"/path/to/your/s3dis/checkpoint/fold_3.ckpt\",\n",
    "    4: \"/path/to/your/s3dis/checkpoint/fold_4.ckpt\",\n",
    "    5: \"/path/to/your/s3dis/checkpoint/fold_5.ckpt\",\n",
    "    6: \"/path/to/your/s3dis/checkpoint/fold_6.ckpt\",\n",
    "}\n",
    "\n",
    "experiment_config = f\"experiment={task_widget.value}/{expe_widget.value}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903673b0-4ad0-4bca-b713-b004a7d03309",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = compute_panoptic_metrics_s3dis_6fold(\n",
    "    fold_ckpt,\n",
    "    experiment_config,\n",
    "    stage='val', \n",
    "    graph_kwargs=dict(\n",
    "        radius=0.1),\n",
    "    partition_kwargs=dict(\n",
    "        regularization=10,\n",
    "        x_weight=1e-3,\n",
    "        cutoff=300),\n",
    "    verbose=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
