{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import laspy, os, sys, random, torch, hydra, gc\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "server = os.path.expanduser(\"~\")\n",
    "from torch_geometric.nn.pool.consecutive import consecutive_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.path.dirname(os.path.abspath('')) \n",
    "sys.path.append(PATH)\n",
    "\n",
    "from src.datasets.dales import CLASS_NAMES as DALES_CLASS_NAMES\n",
    "from src.datasets.dales import CLASS_COLORS as DALES_CLASS_COLORS\n",
    "from src.datasets.kitti360 import CLASS_NAMES as KITTI_CLASS_NAMES\n",
    "from src.datasets.kitti360 import CLASS_COLORS as KITTI_CLASS_COLORS\n",
    "from src.data import Data, InstanceData\n",
    "from src.transforms import instantiate_datamodule_transforms\n",
    "from src.transforms import NAGRemoveKeys\n",
    "from src.utils import init_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Data` reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Dynamic Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_class_mapping(filepath, default_class_id=7):\n",
    "    \"\"\"\n",
    "    Genera las variables de clasificación dinámicamente con base en un archivo LAS/LAZ.\n",
    "    \"\"\"\n",
    "    # Leer el archivo LAS/LAZ\n",
    "    las = laspy.read(filepath)\n",
    "\n",
    "    classifications = las['classification']\n",
    "    unique_classes, counts = np.unique(classifications, return_counts=True)\n",
    "    max_class_id = max(unique_classes) if len(unique_classes) > 0 else 0\n",
    "    ID2TRAINID = np.full(max_class_id + 1, default_class_id, dtype=np.int64)\n",
    "\n",
    "    class_index_mapping = {cls: idx for idx, cls in enumerate(sorted(unique_classes))}\n",
    "    for cls, mapped_idx in class_index_mapping.items():\n",
    "        ID2TRAINID[cls] = mapped_idx\n",
    "\n",
    "    CLASS_NAMES = [f\"Class_{cls}\" for cls in sorted(unique_classes)]\n",
    "    CLASS_COLORS = np.array([[random.randint(0, 255) for _ in range(3)] for _ in unique_classes])\n",
    "\n",
    "    def map_classification(y):\n",
    "        \"\"\"\n",
    "        Mapea la clasificación original a la clase definida en ID2TRAINID.\n",
    "        Si la clasificación no está en el rango, se asigna a 'Default'.\n",
    "        \"\"\"\n",
    "        y_mapped = torch.from_numpy(ID2TRAINID)[y]\n",
    "        y_mapped[y >= len(ID2TRAINID)] = default_class_id\n",
    "        return y_mapped\n",
    "\n",
    "    print(\"Clases encontradas y asignadas:\")\n",
    "    for cls, idx in class_index_mapping.items():\n",
    "        print(f\"Clase {cls} -> Índice {idx} - Color: {CLASS_COLORS[idx]}\")\n",
    "    return ID2TRAINID, CLASS_NAMES, CLASS_COLORS, map_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CTD Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTD_NUM_CLASSES = 7 \n",
    "ID2TRAINID = np.full(65, 0, dtype=np.int64)\n",
    "ID2TRAINID[7] = 1  \n",
    "ID2TRAINID[11] = 1  \n",
    "ID2TRAINID[4] = 2\n",
    "ID2TRAINID[20] = 3\n",
    "ID2TRAINID[8] = 4\n",
    "ID2TRAINID[60] = 5   \n",
    "ID2TRAINID[30] = 6   \n",
    "\n",
    "ID2TRAINID = np.array([0, 1, 2, 3, 4, 5, 6], dtype=np.int64)\n",
    "\n",
    "CTD_CLASS_NAMES = [\n",
    "    'Default',    \n",
    "    'Ground',    \n",
    "    'Building',    \n",
    "    'Pole',    \n",
    "    'Wires',    \n",
    "    'Vegetation',    \n",
    "    'Car',    \n",
    "]\n",
    "\n",
    "CTD_CLASS_COLORS = np.asarray([\n",
    "    [0, 0, 0],   # White\n",
    "    [139, 87, 42],     # Brown\n",
    "    [74, 144, 226],    # Blue\n",
    "    [245, 166, 35],    # Orange\n",
    "    [208, 2, 27],      # Red\n",
    "    [126, 211, 33],    # Green\n",
    "    [248, 231, 28]     # Yellow\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = {\"kitti360\": KITTI_CLASS_NAMES, \"dales\": DALES_CLASS_NAMES, \"ctd\": CTD_CLASS_NAMES}\n",
    "class_colors = {\"kitti360\": KITTI_CLASS_COLORS, \"dales\": DALES_CLASS_COLORS, \"ctd\": CTD_CLASS_COLORS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Las reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ctd360_tile(\n",
    "        filepath, \n",
    "        load_xyz=True, \n",
    "        load_rgb=True, \n",
    "        load_intensity=True, \n",
    "        load_semantic=True, \n",
    "        load_instance=True,\n",
    "        remap_labels=True, \n",
    "        max_intensity=600):\n",
    "    \"\"\"Read a CTD360 tile saved as LAS or LAZ.\"\"\"\n",
    "    \n",
    "    data = Data()\n",
    "\n",
    "    if filepath.lower().endswith('.laz'):\n",
    "        las = laspy.read(filepath, laz_backend=laspy.LazBackend.LazrsParallel)\n",
    "    else:\n",
    "        las = laspy.read(filepath)\n",
    "\n",
    "    if load_xyz:\n",
    "        pos = torch.stack([\n",
    "            torch.tensor(np.copy(las[axis]), dtype=torch.float32)  \n",
    "            for axis in [\"X\", \"Y\", \"Z\"]], dim=-1)\n",
    "        scale = torch.tensor(las.header.scale, dtype=torch.float32)  \n",
    "        pos *= scale\n",
    "        pos_offset = pos[0].clone()  \n",
    "        pos -= pos_offset\n",
    "        data['pos'] = pos\n",
    "\n",
    "    if load_rgb:\n",
    "        if all(axis in las.point_format.dimension_names for axis in ['red', 'green', 'blue']):\n",
    "            data.rgb = torch.stack([\n",
    "                torch.FloatTensor(las[axis].astype('float32') / 65535.0)\n",
    "                for axis in ['red', 'green', 'blue']], dim=-1)\n",
    "        else:\n",
    "            print(\"El archivo LAS no contiene información RGB.\")\n",
    "\n",
    "    if load_intensity:\n",
    "        data.intensity = torch.FloatTensor(\n",
    "            las['intensity'].astype('float32')\n",
    "        ).clip(min=0, max=max_intensity) / max_intensity\n",
    "\n",
    "    if load_semantic:\n",
    "        y = torch.LongTensor(las['classification'])\n",
    "        data.y = torch.from_numpy(ID2TRAINID)[y] if remap_labels else y\n",
    "\n",
    "    # Cargar etiquetas de instancias desde 'user_data'\n",
    "    if load_instance and hasattr(las, 'user_data'):\n",
    "        idx = torch.arange(len(las['user_data']))\n",
    "        obj = torch.LongTensor(las['user_data'])\n",
    "        obj, _ = consecutive_cluster(obj)\n",
    "        count = torch.ones_like(obj)  \n",
    "        if load_semantic:\n",
    "            y = data.y\n",
    "        else:\n",
    "            y = torch.zeros(len(obj), dtype=torch.long)\n",
    "        data.obj = InstanceData(idx, obj, count, y, dense=True)\n",
    "\n",
    "    return data,  pos_offset, scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Data` visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"/home/binahlab/AI-Labs/clever-data/electrical-elements/data/icadel/ibague/ut/raw/pointclouds/UT_CLAS.las\"\n",
    "# ID2TRAINID, ENEL_CLASS_NAMES, ENEL_CLASS_COLORS, map_classification = generate_class_mapping(file_path)\n",
    "# print(\"\\nENEL_CLASS_NAMES:\", ENEL_CLASS_NAMES)\n",
    "# print(\"\\nID2TRAINID:\\n\", ID2TRAINID)\n",
    "# data, _, _ = read_ctd360_tile(file_path, load_semantic=True, load_instance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.y.unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.show(class_names=ENEL_CLASS_NAMES, class_colors=ENEL_CLASS_COLORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"/home/binahlab/AI-Labs/clever-data/electrical-elements/data/celsia/Tolima-2024_08_28/2024_07_12/proccesed/labeling/supervisely/CML-5FFC8A-2024-07-12-16-09-29/ML-5FFC8A-2024-07-12-16-09-29.las\"\n",
    "# data, _, _ = read_ctd360_tile(file_path, load_semantic=True, load_instance=False)\n",
    "# data.show(class_names=CTD_CLASS_NAMES, class_colors=CTD_CLASS_COLORS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single `Inference`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"/home/binahlab/AI-Labs/clever-data/electrical-elements/data/enel/ABC_TRACK_A/raw/pointclouds/ABC_Track_A_FirstProfiler_1.las\"\n",
    "# data, _, _ = read_ctd360_tile(file_path, load_semantic=False, load_instance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = \"kitti360\" \n",
    "# experiment = \"panoptic\"\n",
    "# exp = \"spt-2\" if experiment == \"semantic\" else \"supercluster\"\n",
    "# ckpt_path = f\"{server}/AI-Labs/superpoint_transformer/ckpt/{exp}_{dataset}.ckpt\"\n",
    "# cfg = init_config(overrides=[f\"experiment={experiment}/{dataset}\"])\n",
    "# transforms_dict = instantiate_datamodule_transforms(cfg.datamodule)\n",
    "# model = hydra.utils.instantiate(cfg.model)._load_from_checkpoint(ckpt_path).eval()\n",
    "\n",
    "# nag = transforms_dict['pre_transform'](data)\n",
    "# nag = NAGRemoveKeys(level=0, keys=[k for k in nag[0].keys if k not in cfg.datamodule.point_load_keys])(nag)\n",
    "# nag = NAGRemoveKeys(level='1+', keys=[k for k in nag[1].keys if k not in cfg.datamodule.segment_load_keys])(nag)\n",
    "\n",
    "# nag = nag.cuda()\n",
    "# nag = transforms_dict['on_device_test_transform'](nag)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     output = model(nag)\n",
    "#     nag[0].semantic_pred = output.voxel_semantic_pred(super_index=nag[0].super_index)\n",
    "#     if exp == \"panoptic\":\n",
    "#         vox_labels, vox_instance_idx, vox_instance_data = output.voxel_panoptic_pred(super_index=nag[0].super_index)\n",
    "#         nag[0].semantic_pred = vox_labels\n",
    "#         nag[0].instance_pred = vox_instance_idx\n",
    "#         nag[0].instance_data = vox_instance_data\n",
    "\n",
    "# nag.show(class_names=class_names[dataset], class_colors=class_colors[dataset])\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop route using images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferences and save Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_las_file(tile_data, file_path, classification=None, pos_offset=None, scale=None):\n",
    "    \"\"\"Save the tile data as a .las file.\"\"\"\n",
    "    header = laspy.LasHeader(point_format=tile_data.pos.shape[1])\n",
    "    las = laspy.LasData(header)\n",
    "\n",
    "    # Mover tile_data.pos a la CPU\n",
    "    pos_cpu = tile_data.pos.cpu()\n",
    "\n",
    "    # Restaurar las posiciones originales en la CPU\n",
    "    if pos_offset is not None and scale is not None:\n",
    "        pos_restored = (pos_cpu + pos_offset.cpu()) / scale.cpu()\n",
    "    else:\n",
    "        pos_restored = pos_cpu\n",
    "\n",
    "    # Convertir los datos a numpy y escribirlos en el archivo LAS\n",
    "    las.X = pos_restored[:, 0].numpy()\n",
    "    las.Y = pos_restored[:, 1].numpy()\n",
    "    las.Z = pos_restored[:, 2].numpy()\n",
    "\n",
    "    # Check and save RGB if present\n",
    "    if tile_data.rgb is not None:\n",
    "        las.red = (tile_data.rgb[:, 0].cpu() * 65535).to(torch.int16).numpy().astype(np.uint16)\n",
    "        las.green = (tile_data.rgb[:, 1].cpu() * 65535).to(torch.int16).numpy().astype(np.uint16)\n",
    "        las.blue = (tile_data.rgb[:, 2].cpu() * 65535).to(torch.int16).numpy().astype(np.uint16)\n",
    "\n",
    "    # Check and save intensity if present\n",
    "    if tile_data.intensity is not None:\n",
    "        las.intensity = (tile_data.intensity.cpu() * 600).to(torch.int16).numpy().astype(np.uint16)\n",
    "\n",
    "    # Use provided classification (from inference) or fallback to the original classification in tile_data.y\n",
    "    if classification is not None:\n",
    "        las.classification = classification.cpu().numpy()\n",
    "        print(np.unique(classification.cpu().numpy()))\n",
    "    elif tile_data.y is not None:\n",
    "        las.classification = tile_data.y.cpu().numpy()\n",
    "\n",
    "    # Write the LAS file\n",
    "    las.write(file_path)\n",
    "\n",
    "def map_kitti_to_ctd(vox_labels):\n",
    "    \"\"\"Mapea las clases predichas de KITTI a las clases de ctd.\"\"\"\n",
    "    ctd_labels = torch.full_like(vox_labels, fill_value=0)  # Default (Unclassified)\n",
    "    ctd_labels[vox_labels == -1]= 0   # Noise\n",
    "    ctd_labels[vox_labels == 0] = 1   # Ground\n",
    "    ctd_labels[vox_labels == 1] = 1   # Sidewalk\n",
    "    ctd_labels[vox_labels == 2] = 2   # Building\n",
    "    ctd_labels[vox_labels == 3] = 2   # Wall\n",
    "    ctd_labels[vox_labels == 4] = 2   # Fence\n",
    "    ctd_labels[vox_labels == 5] = 3   # Pole\n",
    "    ctd_labels[vox_labels == 6] = 0   # Traffic light\n",
    "    ctd_labels[vox_labels == 7] = 0   # Traffic sign\n",
    "    ctd_labels[vox_labels == 8] = 5   # Vegetation\n",
    "    ctd_labels[vox_labels == 9] = 5   # Terrain\n",
    "    ctd_labels[vox_labels == 10] = 0  # Person\n",
    "    ctd_labels[vox_labels == 11] = 6  # Car\n",
    "    ctd_labels[vox_labels == 12] = 6  # Truck\n",
    "    ctd_labels[vox_labels >= 13] = 0  # Default\n",
    "    \n",
    "    return ctd_labels\n",
    "\n",
    "def map_dales_to_ctd(vox_labels):\n",
    "    \"\"\"Mapea las clases predichas de DALES a las clases de ctd.\"\"\"\n",
    "    ctd_labels = torch.full_like(vox_labels, fill_value=0)  # Por defecto: Noise (Unclassified)\n",
    "    ctd_labels[vox_labels == 0] = 1   # Ground\n",
    "    ctd_labels[vox_labels == 1] = 5   # Vegetation\n",
    "    ctd_labels[vox_labels == 2] = 6   # Cars\n",
    "    ctd_labels[vox_labels == 3] = 6   # Trucks\n",
    "    ctd_labels[vox_labels == 4] = 4   # Power lines\n",
    "    ctd_labels[vox_labels == 5] = 2   # Fences\n",
    "    ctd_labels[vox_labels == 6] = 3   # Poles\n",
    "    ctd_labels[vox_labels == 7] = 2   # Buildings\n",
    "    ctd_labels[vox_labels == 8] = 0   # Unknown\n",
    "    return ctd_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_and_save_las(\n",
    "    model,\n",
    "    data,\n",
    "    file_path: str,\n",
    "    project_path: str,\n",
    "    transforms_dict: dict,\n",
    "    cfg,\n",
    "    exp: str,\n",
    "    dataset: str,\n",
    "    class_names: dict,\n",
    "    class_colors: dict,\n",
    "    pos_offset,\n",
    "    scale,\n",
    "    visualize: bool = False\n",
    "):\n",
    "    nag = transforms_dict['pre_transform'](data)\n",
    "    nag = NAGRemoveKeys(level=0, keys=[k for k in nag[0].keys if k not in cfg.datamodule.point_load_keys])(nag)\n",
    "    nag = NAGRemoveKeys(level='1+', keys=[k for k in nag[1].keys if k not in cfg.datamodule.segment_load_keys])(nag)\n",
    "\n",
    "    nag = nag.cuda()\n",
    "    nag = transforms_dict['on_device_test_transform'](nag)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(nag)\n",
    "\n",
    "        if exp == \"panoptic\":\n",
    "            vox_labels, vox_instance_idx, vox_instance_data = output.voxel_panoptic_pred(\n",
    "                super_index=nag[0].super_index\n",
    "            )\n",
    "            inf_y = output.full_res_panoptic_pred(\n",
    "                super_index_level0_to_level1=nag[0].super_index,\n",
    "                sub_level0_to_raw=nag[0].sub\n",
    "            )\n",
    "        else:\n",
    "            vox_labels = output.voxel_semantic_pred(super_index=nag[0].super_index)\n",
    "            inf_y = output.full_res_semantic_pred(\n",
    "                super_index_level0_to_level1=nag[0].super_index,\n",
    "                sub_level0_to_raw=nag[0].sub\n",
    "            )\n",
    "\n",
    "        if dataset == 'kitti360':\n",
    "            ctd_labels = map_kitti_to_ctd(inf_y)\n",
    "            ctd_labels_show = map_kitti_to_ctd(vox_labels)\n",
    "        elif dataset == 'dales':\n",
    "            ctd_labels = map_dales_to_ctd(inf_y)\n",
    "            ctd_labels_show = map_dales_to_ctd(vox_labels)\n",
    "        else:\n",
    "            ctd_labels = inf_y\n",
    "            ctd_labels_show = vox_labels\n",
    "\n",
    "    las_name = os.path.basename(file_path)\n",
    "    save_path = os.path.join(project_path, f\"processed/classified_{exp}_{dataset}\")\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    save_las_file(\n",
    "        data,\n",
    "        file_path=os.path.join(save_path, las_name),\n",
    "        classification=ctd_labels,\n",
    "        pos_offset=pos_offset,\n",
    "        scale=scale\n",
    "    )\n",
    "    if visualize:\n",
    "        nag[0].semantic_pred = ctd_labels_show\n",
    "        nag.show(class_names=class_names[\"ctd\"], class_colors=class_colors[\"ctd\"])\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"kitti360\" \n",
    "experiment = \"semantic\"\n",
    "exp = \"spt-2\" if experiment == \"semantic\" else \"supercluster\"\n",
    "ckpt_path = f\"{server}/AI-Labs/superpoint_transformer/ckpt/{exp}_{dataset}.ckpt\"\n",
    "cfg = init_config(overrides=[f\"experiment={experiment}/{dataset}\", f\"datamodule.load_full_res_idx={True}\"])\n",
    "transforms_dict = instantiate_datamodule_transforms(cfg.datamodule)\n",
    "model = hydra.utils.instantiate(cfg.model)._load_from_checkpoint(ckpt_path).eval()\n",
    "project_path = \"/home/binahlab/AI-Labs/clever-data/electrical-elements/data/celsia/Tolima-2024_08_28/2024_07_12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointcloud_dir = Path(project_path) / \"raw\" / \"pointclouds\"\n",
    "las_paths = sorted(list(pointcloud_dir.glob(\"*.las\")) + list(pointcloud_dir.glob(\"*.laz\")))\n",
    "\n",
    "for file_path in las_paths:\n",
    "    print(f\"Procesando: {file_path.name}\")\n",
    "    \n",
    "    try:\n",
    "        data, pos_offset, scale = read_ctd360_tile(str(file_path), load_semantic=False, load_instance=False)\n",
    "\n",
    "        run_inference_and_save_las(\n",
    "            model=model,\n",
    "            data=data,\n",
    "            file_path=str(file_path),\n",
    "            project_path=project_path,\n",
    "            transforms_dict=transforms_dict,\n",
    "            cfg=cfg,\n",
    "            exp=exp,\n",
    "            dataset=dataset,\n",
    "            class_names=class_names,\n",
    "            class_colors=class_colors,\n",
    "            pos_offset=pos_offset,\n",
    "            scale=scale,\n",
    "            visualize=False\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando {file_path.name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
